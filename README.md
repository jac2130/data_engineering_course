# Data Engineering for the 21st Century
The idea for this course is to teach data engineering by building substantively interesting and relatable projects, showing off new and cutting edge methods of data engineering.  These new methods make the discipline easier and more delightful while also adding some powers that have recently been made available by a number of open source communities and by Google. This will include sophisticated pipelining using Apache Beam and Tensorflow as well as Google BigQuery. The goal is to go from ingesting data through ETL, ELT and EL, feature engineering at scale (assuming large datasets that don't fit into memory) through model building and deployments to ultimately arrive at complete data products.      

Data sets that may be used include data on police shootings in the US by Kaggle (https://www.kaggle.com/kwullum/fatal-police-shootings-in-the-us?select=PoliceKillingsUS.csv and https://www.kaggle.com/jpmiller/police-violence-in-the-us) and many public datasets that are already preloaded and freely available in Google BigQuery and that can be easily be pulled into the data warehouse to enrich the Kaggle data sets.  Police shootings and the resulting protests that are the largest in US history are fascinating topics and we will be creating features to predict things such as the number of police shootings and also what characteristics of shootings will most likely lead to large protests.  These outcomes are notoriously difficult to predict and thus we will have a lot of fun trying to do the seemingly impossible.  But importantly, building models will be the least of what we will be doing in this course, where our focus will be on building pipelines and data products.   
